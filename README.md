# K-core-Guided Adaptive Learning and Policy Optimization for Targeted Influence Maximization in Complex Networks

 
## TCQ
<p align="center">
  The repository contains an implementation of <b>Targeted Core-based Q-learning framework (TCQ)</b>,  
  a hybrid optimization approach that draws inspiration from evolutionary network structures derived from <b>K-core decomposition</b>,  
  tailored to tackle the problem of <b>targeted influence maximization (TIM)</b> in complex networks.
</p>
 
 
 
The associated paper to this repository can be found here:<br>
<a href="https://doi.org/10.1016/j.neucom.2025.131612" > K-core-Guided Adaptive Learning and Policy Optimization for Targeted Influence Maximization in Complex Networks  </a> 

 

## Abstract
Maximizing information propagation in complex networks is essential for shaping public discourse, optimizing marketing strategies, and driving social change. Traditional influence maximization approaches often emphasize network topology, neglecting the critical need to align strategies with user semantics to influence specific user groups effectively. To address this issue, we introduce the Targeted Core-based Q-learning framework (TCQ), a hybrid optimization approach that draws inspiration from evolutionary network structures derived from K-core decomposition, tailored to tackle the problem of targeted influence maximization (TIM). TCQ integrates semantic insights (e.g., interests, demographics, or topical categories) with the network structure by combining a target-based probabilistic scoring function with K-core evolutionary hierarchies, enabling the efficient identification of key influential candidates within the network. Leveraging reinforcement learning, TCQ dynamically optimizes its seed selection policy through a process of exploration and exploitation in order to minimize influence overlap among selected seeds while maintaining adaptability across diverse network scenarios. Extensive experiments on real-world and synthetic networks demonstrate that TCQ not only maximizes targeted influence effectively but also achieves computational efficiency, showcasing its potential for optimizing influence propagation in complex networks.

## Keywords
Complex networks 路 Targeted influence maximization路 K-core hierarchies路 Reinforcement learning路 Seed node optimization
  
 
 
![Overview of the TCQ framework](https://github.com/User2021-ai/TCQ/blob/main/Overview%20of%20TCQ.jpg)

Overview of the TCQ framework.

# How to Cite
Please cite the following paper:<br>
<a href="https://doi.org/10.1016/j.neucom.2025.131612" > K-core-Guided Adaptive Learning and Policy Optimization for Targeted Influence Maximization in Complex Networks  </a> 
 


 ```ruby
Ahmad, W., & Wang, B. (2025). K-core-guided adaptive learning and policy optimization for targeted influence maximization in complex networks. Neurocomputing, 131612.

```
BibTeX
```ruby
@article{ahmad2025k,
  title={K-core-guided adaptive learning and policy optimization for targeted influence maximization in complex networks},
  author={Ahmad, Waseem and Wang, Bang},
  journal={Neurocomputing},
  pages={131612},
  year={2025},
  publisher={Elsevier}
}
``` 
 
 
 

# Related Papers
<p>Here are some other papers you might like:</p> <br>

<a href="https://doi.org/10.1016/j.eswa.2024.125393" >A learning-based influence maximization framework for complex networks via K-core hierarchies and reinforcement learning </a>   

 
 





